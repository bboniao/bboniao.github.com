<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
        <title>My Blog</title>
        <description>My Blog - bboniao</description>
        <link>http://bboniao.com</link>
        <link>http://bboniao.com</link>
        <lastBuildDate>2014-04-18T15:55:48+08:00</lastBuildDate>
        <pubDate>2014-04-18T15:55:48+08:00</pubDate>
        <ttl>1800</ttl>


        <item>
                <title>java cpu monitor</title>
                <description>&lt;h3&gt;转自&lt;a href=&quot;http://www.javaarch.net/jiagoushi/55.htm&quot;&gt;java-cpu-monitor shell脚本&lt;/a&gt;&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;#!/bin/bash                                                                                                                           

threshold=${1-95}
now=$(date &amp;#39;+%Y-%m-%d %H:%M:%S&amp;#39;)
cache=()

jps -q | xargs ps hH k -pcpu o pid,lwp,pcpu,args \
  | awk &amp;quot;\$3 &amp;gt;= $threshold&amp;quot; | while read line; do

  array=($(echo &amp;quot;$line&amp;quot;))
  pid=${array[0]}
  lwp=$(printf &amp;#39;%#x&amp;#39; ${array[1]})

  if [ -z &amp;quot;${cache[$pid]}&amp;quot; ]; then
    cache[$pid]=$(jstack $pid)
  fi

  echo &amp;quot;[$now] ${line}&amp;quot;
  echo
  echo &amp;quot;${cache[$pid]}&amp;quot; | sed -n &amp;quot;/nid=$lwp/,/^$/p&amp;quot;
  echo

done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;threshold设置一下cpu的使用率&lt;/p&gt;

&lt;!-- more --&gt;
</description>
                <link>http://bboniao.com/jvm/2014-04/java-cpu-monitor.html</link>
                <guid>http://bboniao.com/jvm/2014-04/java-cpu-monitor</guid>
                <pubDate>2014-04-16T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>HBase在单Column和多Column情况下批量Put的性能对比分析</title>
                <description>&lt;h3&gt;转自&lt;a href=&quot;http://blog.linezing.com/?p=2106&quot;&gt;量子恒道官方博客&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;针对HBase在单column family单column qualifier和单column family多column qualifier两种场景下，分别批量Put写入时的性能对比情况，下面是结合HBase的源码来简单分析解释这一现象。&lt;/p&gt;

&lt;h3&gt;1. 测试结果&lt;/h3&gt;

&lt;p&gt;在客户端批量写入时，单列族单列模式和单列族多列模式的TPS和RPC次数相差很大，以客户端10个线程，开启WAL的两种模式下的测试数据为例，&lt;/p&gt;

&lt;h5&gt;1)单列族单列模式下，TPS能够达到12403.87，实际RPC次数为53次；&lt;/h5&gt;

&lt;h5&gt;2)单列族多列模式下，TPS只有1730.68，实际RPC次数为478次。&lt;/h5&gt;

&lt;p&gt;二者TPS相差约7倍，RPC次数相差约9倍。详细的测试环境这里不再罗列，我们这里关心的只是在两种条件下的性能差别情况。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h3&gt;2. 粗略分析&lt;/h3&gt;

&lt;p&gt;下面我们先从HBase存储原理层面“粗略”分析下为什么出现这个现象：&lt;/p&gt;

&lt;h5&gt;HBase 的KeyValue类中自带的字段占用大小约为50~60 bytes左右（参考HBase源码org/apache/hadoop/hbase/KeyValue.java），那么客户端Put一行数据时（53 个字段，row key为64 bytes，value为751 bytes）：&lt;/h5&gt;

&lt;h5&gt;1)开WAL，单column family单column qualifier，批量Put：(50~60) + 64 + 751 = 865~875 bytes；&lt;/h5&gt;

&lt;h5&gt;2)开WAL，单column family多column qualifier，批量Put：((50~60) + 64) * 53 + 751 = 6793~7323 bytes。&lt;/h5&gt;

&lt;p&gt;因 此，总体来看，后者实际传输的数据量是前者的：(6793~7323 bytes) / (865~875 bytes) = 7.85~8.36倍，与测试结果478 / 53 = 9.0倍基本相符（由于客户端write buffer大小一样，实际请求数的比例关系即代表了实际传输的数据量的比例关系）。&lt;/p&gt;

&lt;h3&gt;3. 源码分析&lt;/h3&gt;

&lt;p&gt;接下来我们通过对HBase的源码分析来进一步验证以上理论估算值：&lt;/p&gt;

&lt;h5&gt;HBase客户端执行put操作后，会调用put.heapSize()累加当前客户端buffer中的数据，满足以下条件则调用flushCommits()将客户端数据提交到服务端：&lt;/h5&gt;

&lt;h5&gt;1)每次put方法调用时可能传入的是一个List&lt;Put&gt;，此时每隔DOPUT&lt;em&gt;WB&lt;/em&gt;CHECK条（默认为10条），检查当前缓存数据是否超过writeBufferSize（测试中被设置为5MB），超过则强制执行刷新；&lt;/h5&gt;

&lt;h5&gt;2)autoFlush被设置为true，此次put方法调用后执行一次刷新；&lt;/h5&gt;

&lt;h5&gt;3)autoFlush被设置为false，但当前缓存数据已超过设定的writeBufferSize，则执行刷新。&lt;/h5&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;private void doPut(final List&amp;lt;Put&amp;gt; puts) throws IOException {
    int n = 0;
    for (Put put : puts) {
        validatePut(put);
        writeBuffer.add(put);
        currentWriteBufferSize += put.heapSize();
        // we need to periodically see if the writebuffer is full instead 
        // of waiting until the end of the List
        n++;
        if (n % DOPUT_WB_CHECK == 0
                &amp;amp;&amp;amp; currentWriteBufferSize &amp;gt; writeBufferSize) {
            flushCommits();
        }
    }
    if (autoFlush || currentWriteBufferSize &amp;gt; writeBufferSize) {
        flushCommits();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;由上述代码可见，通过put.heapSize()累加客户端的缓存数据，作为判断的依据；那么，我们可以按照测试数据的实际情况，编写代码生成Put对象后就能得到测试过程中的一行数据（由53个字段组成，共计731 bytes）实际占用的客户端缓存大小：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.util.Bytes;

public class PutHeapSize {
    /**
     * @param args
     */
    public static void main(String[] args) {
        // single column Put size
        byte[] rowKey = new byte[64];
        byte[] value = new byte[751];
        Put singleColumnPut = new Put(rowKey);
        singleColumnPut.add(Bytes.toBytes(&amp;quot;t&amp;quot;), Bytes.toBytes(&amp;quot;col&amp;quot;), value);
        System.out.println(&amp;quot;single column Put size: &amp;quot; + singleColumnPut.heapSize());

        // multiple columns Put size
        value = null;
        Put multipleColumnsPut = new Put(rowKey);
        for (int i = 0; i &amp;lt; 53; i++) {
            multipleColumnsPut.add(Bytes.toBytes(&amp;quot;t&amp;quot;), Bytes.toBytes(&amp;quot;col&amp;quot; + i), value);
        }
        System.out.println(&amp;quot;multiple columns Put size: &amp;quot; + (multipleColumnsPut.heapSize() + 751));
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;程序输出结果如下：&lt;/p&gt;

&lt;h5&gt;single column Put size: 1208&lt;/h5&gt;

&lt;h5&gt;multiple columns Put size: 10575&lt;/h5&gt;

&lt;p&gt;由运行结果可得到，9719/1192 = 8.75，与上述理论分析值（7.85~8.36倍）、实际测试结果值（9.0倍）十分接近，基本可以验证测试结果的准确性&lt;/p&gt;

&lt;p&gt;如 果你还对put.heapSize()方法感兴趣，可以继续阅读其源码实现，你会发现对于一个put对象来说，其中KeyValue对象的大小最主要决定 了整个put对象的heapSize大小，为了进一步通过实例验证，下面的这段代码分别计算单column和多columns两种情况下一行数据的 KeyValue对象的heapSize大小：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;import org.apache.hadoop.hbase.KeyValue;
public class KeyValueHeapSize {
    /**
     * @param args
     */
    public static void main(String[] args) {

        // single column KeyValue size
        byte[] row = new byte[64]; // test row length
        byte[] family = new byte[1]; // test family length
        byte[] qualifier = new byte[4]; // test qualifier length
        long timestamp = 123456L; // ts
        byte[] value = new byte[751]; // test value length
        KeyValue singleColumnKv = new KeyValue(row, family, qualifier, timestamp, value);
        System.out.println(&amp;quot;single column KeyValue size: &amp;quot; + singleColumnKv.heapSize());

        // multiple columns KeyValue size
        value = null;
        KeyValue multipleColumnsWithoutValueKv = new KeyValue(row, family, qualifier, timestamp, value);
        System.out.println(&amp;quot;multiple columns KeyValue size: &amp;quot; + (multipleColumnsWithoutValueKv.heapSize() * 53 + 751));
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;程序输出结果如下：&lt;/p&gt;

&lt;h5&gt;single column KeyValue size: 920&lt;/h5&gt;

&lt;h5&gt;multiple columns KeyValue size: 10079&lt;/h5&gt;

&lt;p&gt;与前面PutHeapSize程序的输出结果对比发现，KeyValue确实占据了整个Put对象的大部分heapSize空间，同时发现从KeyValue对象级别对比两种情况下的传出数据量情况：10079/920 = 10.9倍，也与实际测试值比较接近。&lt;/p&gt;

&lt;h3&gt;4. 相关结论&lt;/h3&gt;

&lt;p&gt;经过以上分析可以得出以下结论：&lt;/p&gt;

&lt;h5&gt;1)在实际应用场景中，对于单column qualifier和多column qualifier两种情况，如果value长度越长，row key长度越短，字段数（column qualifier数）越少，前者和后者在实际传输数据量上会相差小些；反之则相差较大。&lt;/h5&gt;

&lt;h5&gt;2)如果采用多column qualifier的方式存储，且客户端采取批量写入的方式，则可以根据实际情况，适当增大客户端的write buffer大小，以便能够提高客户端的写入吞吐量。&lt;/h5&gt;
</description>
                <link>http://bboniao.com/hbase/2014-04/hbasecolumncolumnput.html</link>
                <guid>http://bboniao.com/hbase/2014-04/hbasecolumncolumnput</guid>
                <pubDate>2014-04-16T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>hbase delete put的陷阱</title>
                <description>&lt;h3&gt;问题&lt;/h3&gt;

&lt;p&gt;删除数据之后,再插入,查询的时候怎么也找不到.删除和插入都是同一个rowkey,同一个列,同一个版本.&lt;/p&gt;

&lt;h3&gt;原因&lt;/h3&gt;

&lt;p&gt;如果rowkey/family/qulifier/timestamp都一样,多次删除和插入之后,获取哪个值取决于KeyValue.Type.Put之前是Delete就不会被插入了.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h3&gt;分析&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;KeyValue(byte[] row, int roffset, int rlength,  
   byte[] family, int foffset, int flength, byte[] qualifier, int qoffset,  
   int qlength, long timestamp, Type type, byte[] value, int voffset,  
   int vlength)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/images/keyvalue.jpg&quot; alt=&quot;image&quot;&gt;
由代码和图片看出,除了rowkey/family/qulifier/timestamp之外还需要KeyValue.Type才能真正定位到value.想要delete之后还能put,就需要compact,最好major_compact,之后再put就没问题了&lt;/p&gt;
</description>
                <link>http://bboniao.com/hbase/2014-04/hbase-delete-put.html</link>
                <guid>http://bboniao.com/hbase/2014-04/hbase-delete-put</guid>
                <pubDate>2014-04-16T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>为什么要控制hbase cloumnFamily的数量</title>
                <description>&lt;p&gt;设计Hbase schema,要尽量使用一个column family.原因主要是flush和compact机制造成的.&lt;/p&gt;

&lt;p&gt;flush和compact都是基于region级别的:当一个column family数据导入过多,发生flush,也会触发其他所有column family的(此时很小的memstore也会被触发的).而flush会生成很多storefile,紧接着就会触发compact.过多没必要的flush/compact会大大增加io的开销,影响hbase整体性能.&lt;/p&gt;

&lt;!-- more --&gt;
</description>
                <link>http://bboniao.com/hbase/2014-04/hbase-cloumnfamily.html</link>
                <guid>http://bboniao.com/hbase/2014-04/hbase-cloumnfamily</guid>
                <pubDate>2014-04-16T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>memcache使用一致性hash,找出指向的节点</title>
                <description>&lt;h3&gt;代码如下&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;//地址列表
String[] array = addrs.split(&amp;quot;;&amp;quot;);
List&amp;lt;InetSocketAddress&amp;gt; isa = new ArrayList&amp;lt;InetSocketAddress&amp;gt;();
for(int i = 0;i &amp;lt; array.length;i ++){
    String[] addr = array[i].split(&amp;quot;:&amp;quot;);
    isa.add(new InetSocketAddress(addr[0], Integer.parseInt(addr[1])));
}
MemcachedClientBuilder builder = new XMemcachedClientBuilder(isa);
//一致性hash
builder.setSessionLocator(new KetamaMemcachedSessionLocator());
builder.setOpTimeout(200);

builder.build();
String memcacheKey = &amp;quot;test&amp;quot;;
InetSocketAddress i = builder.getSessionLocator().getSessionByKey(memcacheKey).getRemoteSocketAddress();
System.out.println(i.getHostString());
System.out.println(i.getPort());
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;!-- more --&gt;
</description>
                <link>http://bboniao.com/memcache/2014-04/memcachehash.html</link>
                <guid>http://bboniao.com/memcache/2014-04/memcachehash</guid>
                <pubDate>2014-04-14T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>A Better Log4j SMTPAppender</title>
                <description>&lt;h3&gt;log4j配置mail发送log,会有多少发多少,如下改动可以在指定时间内发送指定次数的log&lt;/h3&gt;

&lt;h3&gt;java代码&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;package com.sohu.rc.util;
import org.apache.log4j.net.SMTPAppender;
public class LimitedSMTPAppender extends SMTPAppender {
    private int limit = 10; // max at 10 mails ...
    private int cycleSeconds = 3600; // ... per hour

    public
    LimitedSMTPAppender() {
        this(new LimitedEvaluator());
    }

    public
    LimitedSMTPAppender(TriggeringEventEvaluator evaluator) {
        this.evaluator = evaluator;
    }

    public void setLimit(int limit) {
        this.limit = limit;
    }
    public void setCycleSeconds(int cycleSeconds) {
        this.cycleSeconds = cycleSeconds;
    }
    private int lastVisited;
    private long lastCycle;
    @Override
    protected boolean checkEntryConditions() {
        final long now = System.currentTimeMillis();
        final long thisCycle = now - (now % (1000L * cycleSeconds));
        if (lastCycle != thisCycle) {
            lastCycle = thisCycle;
            lastVisited = 0;
        }
        lastVisited++;
        return super.checkEntryConditions() &amp;amp;&amp;amp; lastVisited &amp;lt;= limit;
    }
}
class LimitedEvaluator implements TriggeringEventEvaluator {
  public boolean isTriggeringEvent(LoggingEvent event) {
    return event.getLevel().isGreaterOrEqual(Level.ERROR);
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;!-- more --&gt;

&lt;h3&gt;log4j.properties的配置&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;log4j.rootLogger=info,mail
log4j.threshhold=ALL

log4j.appender.mail=com.sohu.rc.util.LimitedSMTPAppender
log4j.appender.mail.limit=3
log4j.appender.mail.cycleSeconds=60
log4j.appender.mail.Threshold=ERROR
log4j.appender.mail.BufferSize=32
log4j.appender.mail.From = bboniao@gmail.com
log4j.appender.mail.SMTPHost=10.11.132.229
log4j.appender.mail.Subject=Rc_Strategy_Log4J_Message
log4j.appender.mail.To= bboniao@163.com
log4j.appender.mail.layout=org.apache.log4j.PatternLayout
log4j.appender.mail.layout.ConversionPattern=[%-5p] %d(%r) --&amp;gt; [%t] %l: %m %x %n
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;hadoop/hbase配置&lt;/h3&gt;

&lt;h5&gt;hadoop:打开bin/hadoop-daemon.sh,配置&lt;code&gt;HADOOP_ROOT_LOGGER&lt;/code&gt;&lt;/h5&gt;

&lt;h5&gt;hbase:打开bin/hbase-daemon.sh,配置&lt;code&gt;HBASE_ROOT_LOGGER&lt;/code&gt;&lt;/h5&gt;

&lt;h5&gt;否则log4j.properties中的&lt;code&gt;log4j.rootLogger&lt;/code&gt;不会生效&lt;/h5&gt;

&lt;h5&gt;注意:&lt;code&gt;log4j.appender.mail.Threshold&lt;/code&gt;和&lt;code&gt;this.evaluator&lt;/code&gt;统一&lt;/h5&gt;

&lt;h3&gt;&lt;a href=&quot;http://blog.cherouvim.com/a-better-smtpappender/&quot;&gt;参考链接&lt;/a&gt;&lt;/h3&gt;
</description>
                <link>http://bboniao.com/java/2014-04/a-better-log4j-smtpappender.html</link>
                <guid>http://bboniao.com/java/2014-04/a-better-log4j-smtpappender</guid>
                <pubDate>2014-04-12T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>Kill Zombie Process</title>
                <description>&lt;h3&gt;查找僵尸进程&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;ps aux |awk &amp;#39;{print $8 &amp;quot; &amp;quot; $2}&amp;#39; |grep -w Z&lt;/code&gt;&lt;/p&gt;

&lt;h3&gt;查找此进程信息和父进程pid&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;ps -ef |grep $pid&lt;/code&gt;&lt;/p&gt;

&lt;!-- more --&gt;
</description>
                <link>http://bboniao.com/linux/2014-04/kill-zombie-process.html</link>
                <guid>http://bboniao.com/linux/2014-04/kill-zombie-process</guid>
                <pubDate>2014-04-01T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>记录一次resin load过高的解决过程</title>
                <description>&lt;h5&gt;1.使用&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/download/0.2.6/housemd-0.2.6.zip&quot;&gt;housemd&lt;/a&gt;统计方法耗时,&lt;a href=&quot;https://github.com/CSUG/HouseMD/wiki/UserGuideCN&quot;&gt;中文说明&lt;/a&gt;&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;./housewd $jvm_pid&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;trace -d  -l 50000 -t 50000 ClassName&lt;/code&gt;&lt;/p&gt;

&lt;h5&gt;2.使用ss统计tcp信息,参照&lt;a href=&quot;http://www.ttlsa.com/linux-command/ss-replace-netstat/&quot;&gt;文章&lt;/a&gt;&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;ss -s&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ss -t -a | grep ESTAB&lt;/code&gt;&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h5&gt;3.统计java各个线程的个数&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;jstack $jvm_pid | grep &amp;#39;nid=&amp;#39; | awk -F &amp;#39;-&amp;#39; &amp;#39;{print $1}&amp;#39; | awk &amp;#39;{++S[$0]} END {for (a in S) print S[a],a}&amp;#39; | sort -nr&lt;/code&gt;&lt;/p&gt;

&lt;h5&gt;4.统计各个状态线程的个数&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;jstack $jvm_pid | grep java.lang.Thread.State | awk &amp;#39;{++S[$0]} END {for (a in S) print S[a],a}&amp;#39; | sort -nr&lt;/code&gt;&lt;/p&gt;

&lt;h5&gt;5.查找哪些线程cpu使用过高&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;jstack $jvm_pid &amp;gt; jstack01 &amp;amp;&amp;amp; ps mp $jvm_pid -o THREAD,tid,time | sort -k2nr | awk &amp;#39;{printf(&amp;quot;%x&amp;quot;,$8)}{print &amp;quot; &amp;quot;,($2&amp;quot;%&amp;quot;),&amp;quot; &amp;quot;,$9}&amp;#39; | head -30&lt;/code&gt;&lt;/p&gt;
</description>
                <link>http://bboniao.com/java/2014-03/resin-load.html</link>
                <guid>http://bboniao.com/java/2014-03/resin-load</guid>
                <pubDate>2014-03-23T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>jmeter使用</title>
                <description>&lt;h3&gt;1.pom.xml引入依赖&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.apache.jmeter&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;ApacheJMeter_java&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;${apache.jmeter.version}&amp;lt;/version&amp;gt;
    &amp;lt;/dependency&amp;gt;

    &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.apache.jmeter&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;ApacheJMeter_core&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;${apache.jmeter.version}&amp;lt;/version&amp;gt;
    &amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;!-- more --&gt;

&lt;h3&gt;2.实现接口&lt;code&gt;org.apache.jmeter.protocol.java.sampler.AbstractJavaSamplerClient&lt;/code&gt;&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;public class HbaseServiceLoadMeter extends AbstractJavaSamplerClient {

    public  HTablePool majorHpool;
    public  HTablePool mapHpool;

    /**
     * 初始化
     */
    @Override
    public void setupTest(JavaSamplerContext context) {
        Configuration majorConf = HBaseConfiguration.create();
        majorConf.addResource(&amp;quot;hbase-site-92.xml&amp;quot;);
        this.majorHpool = new HTablePool(majorConf, 512);

        Configuration mapConf = HBaseConfiguration.create();
        mapConf.addResource(&amp;quot;map-hbase-site.xml&amp;quot;);
        this.mapHpool = new HTablePool(mapConf, 512);
    }

    /**
     * 指定各种参数和默认值.可以在GUI中动态指定.
     */
    @Override
    public Arguments getDefaultParameters() {
        Arguments arguments = new Arguments();
        arguments.addArgument(&amp;quot;p&amp;quot;, &amp;quot;&amp;quot;);
        arguments.addArgument(&amp;quot;y&amp;quot;, &amp;quot;&amp;quot;);
        arguments.addArgument(&amp;quot;u&amp;quot;, &amp;quot;&amp;quot;);
        return arguments;
    }

    /**
     * 测试代码调用逻辑
     */
    @Override
    public SampleResult runTest(JavaSamplerContext context) {
        SampleResult sr = new SampleResult();
        // Start
        sr.sampleStart();
        try {
            String y = context.getParameter(&amp;quot;y&amp;quot;);
            String u = context.getParameter(&amp;quot;u&amp;quot;);
            String p = context.getParameter(&amp;quot;p&amp;quot;);

            Long ukey = getUkey(p, y, u);
            sr.setSuccessful(getRcEntire(ukey));
        } catch (Exception e) {
            getLogger().error(e.getMessage(), e);
            sr.setSuccessful(false);
        } finally {
            sr.sampleEnd();
        }
        return sr;
    }

    private boolean getRcEntire(Long ukey) {
    }

    private Long getUkey(String p, String y, String u) {

    }

    private Long getCommonUkey(String rowkey, String family) {

    }

    /**
     * 测试结束清理方法,全局调用一次
     *
     */
    @Override
    public void teardownTest(JavaSamplerContext context) {
        try {
            this.majorHpool.close();
            this.mapHpool.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;3.打成jar包,以及依赖的jar包放到jmeter安装目录下的&lt;code&gt;lib/ext&lt;/code&gt;&lt;/h3&gt;

&lt;h3&gt;4.打开jmeter.新建&lt;code&gt;Test Plan&lt;/code&gt;&lt;/h3&gt;

&lt;h3&gt;5.在&lt;code&gt;Test Plan&lt;/code&gt;下,新建&lt;code&gt;Thread Group&lt;/code&gt;,设置&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;Number of Threads(users)
Ramp-Up Period(in seconds)
Loop Count
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;6.在&lt;code&gt;Thread Group&lt;/code&gt;下,新建&lt;code&gt;Java Request&lt;/code&gt;,设置&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;ClassName
Send Parameters With the Request(接口AbstractJavaSamplerClient的getDefaultParameters方法定义的)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;7.在&lt;code&gt;Java Request&lt;/code&gt;下,新建&lt;code&gt;CSV Data Set Config&lt;/code&gt;,指定参数的输入文件,设置&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;Filename
File encoding
Variable Names(comma-delimited)
Delimiter(use&amp;#39;\t&amp;#39; for tab)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;8.在&lt;code&gt;Java Request&lt;/code&gt;下,新建&lt;code&gt;Aggregate Report&lt;/code&gt;,统计压测效果&lt;/h3&gt;

&lt;h3&gt;9.&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/download/rc_entire_0.96.jmx/rc_entire_0.96.jmx&quot;&gt;配置文件样例&lt;/a&gt;&lt;/h3&gt;

&lt;h3&gt;10.终端下,执行命令:&lt;code&gt;jmeter -n -t rc_entire_0.96.jmx -l log.jtl&lt;/code&gt;,rc&lt;em&gt;entire&lt;/em&gt;0.96.jmx是GUI配置后生成的,log.jtl是结果文件,使用GUI查看比较方便&lt;/h3&gt;

&lt;h3&gt;11.&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/download/ifox.home.jmx/ifox.home.jmx&quot;&gt;HTTP配置文件样例&lt;/a&gt;&lt;/h3&gt;
</description>
                <link>http://bboniao.com/java/2014-03/jmeter.html</link>
                <guid>http://bboniao.com/java/2014-03/jmeter</guid>
                <pubDate>2014-03-15T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>hadoop2和hbase0.96的配置</title>
                <description>&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;left&quot;&gt;集群&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;hadoop&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;hbase&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;资料库&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/tag/hadoop1.major.conf&quot;&gt;hadoop-1.0.3&lt;/a&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/tag/hbase92.major.conf&quot;&gt;hbase-0.92.1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;标示库&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/tag/hadoop1.map.conf&quot;&gt;hadoop-1.0.3&lt;/a&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/tag/hbase92.map.conf&quot;&gt;hbase-0.92.1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;测试库&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/tag/hadoop2.conf&quot;&gt;hadoop-2.2.0&lt;/a&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/tag/hbase96.conf&quot;&gt;hbase-0.96.1&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;!-- more --&gt;
</description>
                <link>http://bboniao.com/hadoop/2014-03/hadoop2hbase096.html</link>
                <guid>http://bboniao.com/hadoop/2014-03/hadoop2hbase096</guid>
                <pubDate>2014-03-15T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>hadoop2 compile</title>
                <description>&lt;h3&gt;使用Maven 3.0&lt;/h3&gt;

&lt;h3&gt;安装依赖的包:&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum install gcc-c++ cmake zlib-devel
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;安装protobuf&lt;/h3&gt;

&lt;h3&gt;编辑hadoop-common-project/hadoop-auth/pom.xml.添加&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.mortbay.jetty&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;jetty-util&amp;lt;/artifactId&amp;gt;
  &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;执行命令:&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;mvn package -Pdist,native -DskipTests -Dtar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;编译好的tar在hadoop-common-project/hadoop-common/target&lt;/h3&gt;

&lt;!-- more --&gt;
</description>
                <link>http://bboniao.com/hadoop/2014-03/hadoop2-compile.html</link>
                <guid>http://bboniao.com/hadoop/2014-03/hadoop2-compile</guid>
                <pubDate>2014-03-15T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>Linux小技巧</title>
                <description>&lt;h3&gt;查找wio过高进程&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;/etc/init.d/syslog stop&lt;/li&gt;
&lt;li&gt;echo 1 &amp;gt; /proc/sys/vm/block_dump&lt;/li&gt;
&lt;li&gt;dmesg | egrep &amp;quot;READ|WRITE|dirtied&amp;quot; | egrep -o &amp;#39;([a-zA-Z]*)&amp;#39; | sort | uniq -c | sort -rn | head&lt;/li&gt;
&lt;li&gt;echo 0 &amp;gt; /proc/sys/vm/block_dump&lt;/li&gt;
&lt;li&gt;/etc/init.d/syslog start&lt;/li&gt;
&lt;/ol&gt;

&lt;!-- more --&gt;

&lt;h3&gt;Linux分析jvm的cpu性能瓶颈&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;使用ps aux找到jvm的pid&lt;/li&gt;
&lt;li&gt;执行top -H -p &amp;lt;pid&amp;gt;，可显示出该进程下的所有线程。找到占用cpu最多的子线程pid，并将其转换为16进制&lt;/li&gt;
&lt;li&gt;jstack &amp;lt;pid&amp;gt; 查找&amp;quot;nid=16进制子pid&amp;quot;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;memcache的启动参数&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;/opt/memcache/bin/memcached -d -f 1.1 -M -m 4096 -o slab_reassign slab_automove -u root -l 10.11.6.31 -p 12336 -c 1024 -P /opt/memcache/memcached.pid
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;left&quot;&gt;参数&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-d&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;守护进程方式启动&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-f&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;增长因子&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-M&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;内存用光时报错&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-m&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;使用内存大小,单位m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-o&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;子参数:slab&lt;em&gt;reassign,slab&lt;/em&gt;automove,cache就会以每10秒一次的频率进行重分配&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-u&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;启动的用户&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-l&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;绑定地址&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-p&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;绑定端口&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-c&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;连接数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-P&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;pid保存文件&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
</description>
                <link>http://bboniao.com/linux/2014-03/linux-trip.html</link>
                <guid>http://bboniao.com/linux/2014-03/linux-trip</guid>
                <pubDate>2014-03-13T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>JVM常用的参数说明</title>
                <description>&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;left&quot;&gt;参数&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-Djava.io.tmpdir&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;指定目录,可以避免jps找不到pid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:+PrintFlagsFinal&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;打印jvm参数的默认值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:+PrintCommandLineFlags&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;打印与默认值不同的参数&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;!-- more --&gt;
</description>
                <link>http://bboniao.com/jvm/2014-03/jvm-parameter.html</link>
                <guid>http://bboniao.com/jvm/2014-03/jvm-parameter</guid>
                <pubDate>2014-03-13T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>Java Mission Control</title>
                <description>&lt;h3&gt;Mac上使用&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;下载&lt;code&gt;jdk7u40&lt;/code&gt;以后的版本,执行jmc.mac os上暂时用不了,但可以用方法2&lt;/li&gt;
&lt;li&gt;使用eclipse:
&lt;a href=&quot;http://archive.eclipse.org/eclipse/downloads/drops/R-3.8-201206081200/download.php?dropFile=eclipse-platform-3.8-macosx-cocoa-x86_64.tar.gz&quot;&gt;eclipse3.8&lt;/a&gt;
使用其他平台jdk的jmc更新完插件,拷贝JAVA_HOME/lib/missioncontrol/plugins下的jar包到eclipse/plugins即可&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;启动Java Flight Recorder (JFR)&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;启动参数:&lt;/p&gt;

&lt;p&gt;-Dcom.sun.management.jmxremote.port=7091 -Dcom.sun.management.jmxremote.rmi.port=7091 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false  -XX:+UnlockCommercialFeatures -XX:+FlightRecorder&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;!-- more --&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;启动代理(5596是jvm的pid,jvm启动时必须添加-XX:+UnlockCommercialFeatures -XX:+FlightRecorder):&lt;/p&gt;

&lt;p&gt;jcmd 5596 ManagementAgent.start jmxremote.ssl=false jmxremote.port=7091 jmxremote.rmi.port=7091 jmxremote.authenticate=false jmxremote.autodiscovery=true &lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
                <link>http://bboniao.com/jvm/2014-03/java-mission-control.html</link>
                <guid>http://bboniao.com/jvm/2014-03/java-mission-control</guid>
                <pubDate>2014-03-11T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>jekyll使用七牛的CDN</title>
                <description>&lt;h3&gt;注册七牛&lt;/h3&gt;

&lt;p&gt;进入&lt;a href=&quot;https://portal.qiniu.com/&quot;&gt;七牛的用户界面&lt;/a&gt;,创建一个空间,访问控制选择公开,然后点击一键加速网站,填写你的网站地址&lt;/p&gt;

&lt;h3&gt;修改_config.xml&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;safe: false
cdn_url : http://bboniao.qiniudn.com
JB :
ASSET_PATH : false
IMAGE_PATH : false
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;!-- more --&gt;

&lt;h3&gt;修改_includes/JB/setup,&lt;/h3&gt;

&lt;p&gt;这样的好处本地不会使用cdn,而发布到githup上使用&lt;code&gt;site.cdn_url&lt;/code&gt;上的资源&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/qiniu-cdn-jekyll-code.png&quot; alt=&quot;image&quot;&gt;&lt;/p&gt;

&lt;h3&gt;说明&lt;/h3&gt;

&lt;p&gt;/assets和/images下的资源会缓存到cdn,使用的时候用 {{ ASSET&lt;em&gt;PATH }} 和 {{ IMAGE&lt;/em&gt;PATH }} 来代替.更改缓存的内容时,需要到七牛后台界面的空间设置--高级设置--去刷新&lt;/p&gt;
</description>
                <link>http://bboniao.com/jekyll/2014-03/jekyllcdn.html</link>
                <guid>http://bboniao.com/jekyll/2014-03/jekyllcdn</guid>
                <pubDate>2014-03-09T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>常用工具包收集</title>
                <description>&lt;p&gt;&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/download/gcviewer-1.34-SNAPSHOT/gcviewer-1.34-SNAPSHOT.jar&quot;&gt;GC Log分析工具,支持G1.&lt;/a&gt;
&lt;a href=&quot;https://github.com/chewiebug/GCViewer&quot;&gt;code地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/download/tdv1.1/tdv1.1.jar&quot;&gt;Thread Dump Viewer.&lt;/a&gt;
&lt;a href=&quot;http://sourceforge.net/projects/tdv/&quot;&gt;code地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/download/tda2.2/tda.jar&quot;&gt;Thread Dump Analyzer.&lt;/a&gt;
&lt;a href=&quot;http://sourceforge.net/projects/tdv/&quot;&gt;code地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/download/gchisto/gchisto.jar&quot;&gt;GC Histogram Tool,不支持G1.&lt;/a&gt;
&lt;a href=&quot;https://svn.java.net/svn/tda%7Esvn&quot;&gt;code地址&lt;/a&gt;&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/download/cmdline-jmxclient-0.10.3/cmdline-jmxclient-0.10.3.jar&quot;&gt;shell 调用jmx接口&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/bboniao/bboniao.github.com/releases/download/0.2.6/housemd-0.2.6.zip&quot;&gt;Java进程运行时诊断和调试工具&lt;/a&gt;
&lt;a href=&quot;https://github.com/CSUG/HouseMD&quot;&gt;code地址&lt;/a&gt;&lt;/p&gt;
</description>
                <link>http://bboniao.com/tools/2014-03/tools.html</link>
                <guid>http://bboniao.com/tools/2014-03/tools</guid>
                <pubDate>2014-03-07T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>G1(Garbage First)的使用</title>
                <description>&lt;h3&gt;为什么采用G1&lt;/h3&gt;

&lt;p&gt;Hbase开启SLAB之后还是会产生很多碎片,导致Full GC.原因是BlockCache产生很多碎片,CMS对碎片无能为力.采用G1吞吐量与CMS相当&lt;/p&gt;

&lt;h3&gt;我的参数配置(g1和cms)&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;-Xmx24g -Xms24g -XX:PermSize=96m -XX:MaxPermSize=96m -XX:+UseG1GC -XX:SurvivorRatio=6 -XX:MaxGCPauseMillis=400 -XX:G1ReservePercent=15  -XX:InitiatingHeapOccupancyPercent=40 -XX:ConcGCThreads=8

-Xmx24g -Xms24g -Xmn5g -XX:PermSize=96m -XX:MaxPermSize=96m -XX:SurvivorRatio=2 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=68 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=0 -XX:+CMSConcurrentMTEnabled -XX:PretenureSizeThreshold=2097151 -XX:MaxTenuringThreshold=6 -XX:-OmitStackTraceInFastThrow -XX:+CMSScavengeBeforeRemark
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;新生代和region大小没有指定,G1可以更好的自动分配资源.&lt;/li&gt;
&lt;li&gt;提高MaxGCPauseMillis,实时性要求没有太严格,可以提高吞吐量&lt;/li&gt;
&lt;li&gt;提高G1ReservePercent,降低InitiatingHeapOccupancyPercent,提高ConcGCThreads因为遇到内存不足而产生了Full GC&lt;/li&gt;
&lt;/ol&gt;

&lt;!-- more --&gt;

&lt;h3&gt;G1常用参数&lt;/h3&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;left&quot;&gt;参数&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:+UseG1GC&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;开启G1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:MaxGCPauseMillis=n&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;设置GC暂停的最大时间,这只是目标,尽量达到,默认值是 200 毫秒,&lt;code&gt;过小影响吞吐量&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:InitiatingHeapOccupancyPercent=n&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;整个堆(而不是某个年代)使用量达到此值,便会触发并发GC周期.值为0则是连续触发,默认值为45&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:NewRatio=n&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;老年代与新生代的比值,默认值为2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:SurvivorRatio=n&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;伊甸园代与生存代的比率,默认值为8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:MaxTenuringThreshold=n&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;生存代存活的最大门限,默认值为15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:ParallelGCThreads=n&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;设置垃圾回收器并行阶段的线程数,默认值与JVM运行的平台有关,&lt;code&gt;将 n 的值设置为逻辑处理器的数量&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:ConcGCThreads=n&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;设置并发垃圾回收器使用的线程数,默认值与JVM运行的平台有关&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:G1ReservePercent=n&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;设置剩余的内存量,减少跃迁失败的可能,默认值为10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;-XX:G1HeapRegionSize=n&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;设置G1平分java堆而产生区域的大小,默认值可以提供最大的工效性.最小值为1M,最大为32M,最多划分1024个,&lt;code&gt;建议使用默认值&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h3&gt;标记周期的各个阶段&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;初始标记阶段：&lt;/strong&gt;在此阶段，G1 GC 对根进行标记。该阶段与常规的 (&lt;code&gt;STW&lt;/code&gt;) 年轻代垃圾回收密切相关。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;根区域扫描阶段：&lt;/strong&gt;G1 GC 在初始标记的存活区扫描对老年代的引用，并标记被引用的对象。该阶段与应用程序（&lt;code&gt;非STW&lt;/code&gt;）同时运行，并且只有完成该阶段后，才能开始下一次 &lt;code&gt;STW&lt;/code&gt; 年轻代垃圾回收。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;并发标记阶段：&lt;/strong&gt;G1 GC 在整个堆中查找可访问的（存活的）对象。该阶段与应用程序同时运行，可以被 &lt;code&gt;STW&lt;/code&gt; 年轻代垃圾回收中断。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;重新标记阶段：&lt;/strong&gt;该阶段是 &lt;code&gt;STW&lt;/code&gt; 回收，帮助完成标记周期。G1 GC 清空 SATB 缓冲区，跟踪未被访问的存活对象，并执行引用处理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;清理阶段：&lt;/strong&gt;在这个最后阶段，G1 GC 执行统计和 RSet 净化的 &lt;code&gt;STW&lt;/code&gt; 操作。在统计期间，G1 GC 会识别完全空闲的区域和可供进行混合垃圾回收的区域。清理阶段在将空白区域重置并返回到空闲列表时为部分并发。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;内存用尽造成Full GC&lt;/h3&gt;

&lt;p&gt;查找&lt;code&gt;to-space exhausted&lt;/code&gt;和&lt;code&gt;to-space overflow&lt;/code&gt;,表示因内存不够产生Full GC&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;-XX:G1ReservePercent 增加预存内存量&lt;/li&gt;
&lt;li&gt;-XX:InitiatingHeapOccupancyPercent 减少此值,提前启动标记周期&lt;/li&gt;
&lt;li&gt; -XX:ConcGCThreads 增加并行标记线程的数目&lt;/li&gt;
&lt;/ol&gt;
</description>
                <link>http://bboniao.com/jvm/2014-03/g1garbage-first.html</link>
                <guid>http://bboniao.com/jvm/2014-03/g1garbage-first</guid>
                <pubDate>2014-03-07T00:00:00+08:00</pubDate>
        </item>


</channel>
</rss>
